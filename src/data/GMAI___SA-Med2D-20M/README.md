# [SA-Med2D-20M](https://arxiv.org/abs/2311.11969)

![Image](https://raw.githubusercontent.com/OpenGVLab/SAM-Med2D/main/assets/cover_SA-Med2D-20M.png)

The largest benchmark dataset for segmentation in the field of medical imaging.

As is well known, the emergence of ImageNet has greatly propelled the development of AI, especially deep learning. It has provided massive data and powerful baseline models for the computer vision community, enabling researchers to achieve breakthroughs in tasks such as natural image classification, segmentation, and detection. However, in the medical image realm, there lack of such a large dataset for developing powerful medical models.

To address the gap in the medical field, we are introducing the largest benchmark dataset for medical image segmentation. This initiative aims to drive the rapid development of AI in healthcare and accelerate the transformation of computational medicine towards a more inclusive direction.

Please visit the [GitHub](https://github.com/OpenGVLab/SAM-Med2D) page and further exploit the dataset!

Due to data privacy and ethical requirements, we currently only provide access to a 16M dataset. We will keep updating and maintaining this database. Please stay tuned for further updates from us.


## ğŸ‘‰ Filesystem Hierarchy
```bash
~/SAM-Med2D-20M
â”œâ”€â”€ images
|      â”œâ”€â”€ mr_00--ACDC--patient001_frame01--x_0006.png
|      â”œâ”€â”€ mr_t1--BraTS2021--BraTS2021_00218--z_0141.png
|      â”œâ”€â”€ ...
|      â”œâ”€â”€ ct_00--CAD_PE--001--x_0125.png
|      â”œâ”€â”€ x_ray--covid_19_ct_cxr--16660_5_1--2d_none.png
|
â”œâ”€â”€ masks
|      â”œâ”€â”€ mr_00--ACDC--patient001_frame01--x_0006--0000_000.png
|      â”œâ”€â”€ mr_t1--BraTS2021--BraTS2021_00218--z_0141--0011_000.png
|      â”œâ”€â”€ ...
|      â”œâ”€â”€ ct_00--CAD_PE--001--x_0125--0000_002.png
|      â”œâ”€â”€ x_ray--covid_19_ct_cxr--16660_5_1--2d_none--0000_001.png 
|
â”œâ”€â”€ SAMed2D_v1_class_mapping_id.json
|
â”œâ”€â”€ SAMed2D_v1.json

```
The SA-Med2D-20M dataset is named following the convention below:
```bash
-images
  -{modality_sub-modality}--{dataset name}--{ori name}--{dimension_slice}.png

-masks
  -{modality_sub-modality}--{dataset name}--{ori name}--{dimension_slice}--{class instance_id}.png
```
Note: "sub-modality" applies only to 3D data, and when "sub-modality" is "00," it indicates either the absence of a sub-modality or an unknown sub-modality type. "dataset name" refers to the specific dataset name that the case is from. "ori name" is the original case name in its dataset. "dimension slice", e.g., "x_100", indicates the dimension along which we split a 3D case as well as the slice ID in this dimension. If we split a 3D case with axis x and the current slice is 100, then the term can be "x_0100". For 2D datasets, the "dimension_slice id" is uniformly set to "2d_none".  "class instance_id", unique to masks, encapsulates both category information and instance id, and the detailed information is stored in the "SAMed2D_v1_class_mapping_id.json" file. For instance, if the category "liver" is assigned the ID "0003" and there is only one instance of this category in the case, the "class instance_id" can be denoted as "0003_000". Besides, the category "liver" in the "SAMed2D_v1_class_mapping_id.json" file is formulated as key-value pair with _python-dict_ format: \{"liver": "0003"\}.

The file "SAMed2D_v1_class_mapping_id.json" stores the information for converting class instances. The file "SAMed2D_v1.json" contains the path information for all image and mask pairs.

## ğŸ‘‰ Unzipping split zip files
Windows:

    decompress SA-Med2D-16M.zip to automatically extract the other volumes together.

Linux: 

    1. zip SA-Med2D-16M.zip SA-Med2D-16M.z0* SA-Med2D-16M.z10 -s=0 --out {full}.zip
    
    2. unzip {full}.zip



## ğŸ¤ å…è´£å£°æ˜
- SA-Med2D-20Mæ˜¯ç”±å¤šä¸ªå…¬å¼€çš„æ•°æ®é›†ç»„æˆï¼Œæ—¨åœ¨å–ä¹‹äºç¤¾åŒºï¼Œå›é¦ˆäºç¤¾åŒºï¼Œä¸ºç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æä¾›ä¸€ä¸ªç”¨äºå­¦æœ¯å’ŒæŠ€æœ¯ç ”ç©¶çš„èµ„æºã€‚ä½¿ç”¨æœ¬æ•°æ®é›†çš„ä»»ä½•ä¸ªäººæˆ–ç»„ç»‡ï¼ˆä»¥ä¸‹ç»Ÿç§°ä¸ºâ€œä½¿ç”¨è€…â€ï¼‰éœ€éµå®ˆä»¥ä¸‹å…è´£å£°æ˜ï¼š
1. æ•°æ®é›†æ¥æºï¼šæœ¬æ•°æ®é›†ç”±å¤šä¸ªå…¬å¼€çš„æ•°æ®é›†ç»„æˆï¼Œè¿™äº›æ•°æ®é›†çš„æ¥æºå·²åœ¨é¢„å°ç‰ˆè®ºæ–‡ä¸­æ˜ç¡®æ ‡æ˜ã€‚ä½¿ç”¨è€…åº”å½“éµå®ˆåŸå§‹æ•°æ®é›†çš„ç›¸å…³è®¸å¯å’Œä½¿ç”¨æ¡æ¬¾ã€‚
2. æ•°æ®å‡†ç¡®æ€§ï¼šå°½ç®¡æˆ‘ä»¬å·²ç»åŠªåŠ›ç¡®ä¿æ•°æ®é›†çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§ï¼Œä½†æ— æ³•å¯¹æ•°æ®é›†çš„å‡†ç¡®æ€§ä½œå‡ºä¿è¯ã€‚ä½¿ç”¨è€…åº”è‡ªè¡Œæ‰¿æ‹…ä½¿ç”¨æ•°æ®é›†å¯èƒ½å¸¦æ¥çš„é£é™©å’Œè´£ä»»ã€‚
3. è´£ä»»é™åˆ¶ï¼šåœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œæ•°æ®é›†çš„æä¾›è€…åŠç›¸å…³è´¡çŒ®è€…å‡ä¸å¯¹ä½¿ç”¨è€…çš„ä»»ä½•è¡Œä¸ºæˆ–ç»“æœæ‰¿æ‹…è´£ä»»ã€‚
4. ä½¿ç”¨çº¦æŸï¼šä½¿ç”¨è€…åœ¨ä½¿ç”¨æœ¬æ•°æ®é›†æ—¶ï¼Œåº”éµå®ˆé€‚ç”¨çš„æ³•å¾‹æ³•è§„å’Œä¼¦ç†è§„èŒƒã€‚ä½¿ç”¨è€…ä¸å¾—å°†æœ¬æ•°æ®é›†ç”¨äºéæ³•ã€ä¾µçŠ¯éšç§ã€è¯½è°¤ã€æ­§è§†æˆ–å…¶ä»–è¿æ³•æˆ–ä¸é“å¾·çš„ç›®çš„ã€‚
5. çŸ¥è¯†äº§æƒï¼šæœ¬æ•°æ®é›†çš„çŸ¥è¯†äº§æƒå½’åŸå§‹æ•°æ®é›†çš„ç›¸å…³æƒåˆ©äººæ‰€æœ‰ï¼Œä½¿ç”¨è€…ä¸å¾—ä»¥ä»»ä½•æ–¹å¼ä¾µçŠ¯æ•°æ®é›†çš„çŸ¥è¯†äº§æƒã€‚

- ä½œä¸ºéç›ˆåˆ©æœºæ„ï¼Œå›¢é˜Ÿå€¡å¯¼å’Œè°å‹å¥½çš„å¼€æºäº¤æµç¯å¢ƒï¼Œè‹¥åœ¨å¼€æºæ•°æ®é›†å†…å‘ç°æœ‰ä¾µçŠ¯æ‚¨åˆæ³•æƒç›Šçš„å†…å®¹ï¼Œå¯å‘é€é‚®ä»¶è‡³(yejin@pilab.org.cn, chengjunlong@pilab.org.cn)ï¼Œé‚®ä»¶ä¸­è¯·å†™æ˜ä¾µæƒç›¸å…³äº‹å®çš„è¯¦ç»†æè¿°å¹¶å‘æˆ‘ä»¬æä¾›ç›¸å…³çš„æƒå±è¯æ˜èµ„æ–™ã€‚æˆ‘ä»¬å°†äº3ä¸ªå·¥ä½œæ—¥å†…å¯åŠ¨è°ƒæŸ¥å¤„ç†æœºåˆ¶ï¼Œå¹¶é‡‡å–å¿…è¦çš„æªæ–½è¿›è¡Œå¤„ç½®(å¦‚ä¸‹æ¶ç›¸å…³æ•°æ®)ã€‚ä½†åº”ç¡®ä¿æ‚¨æŠ•è¯‰çš„çœŸå®æ€§ï¼Œå¦åˆ™é‡‡å–æªæ–½åæ‰€äº§ç”Ÿçš„ä¸åˆ©åæœåº”ç”±æ‚¨ç‹¬ç«‹æ‰¿æ‹…ã€‚

- é€šè¿‡ä¸‹è½½ã€å¤åˆ¶ã€è®¿é—®æˆ–ä½¿ç”¨æœ¬æ•°æ®é›†ï¼Œå³è¡¨ç¤ºä½¿ç”¨è€…å·²é˜…è¯»ã€ç†è§£å¹¶åŒæ„éµå®ˆæœ¬å…è´£å£°æ˜ä¸­çš„æ‰€æœ‰æ¡æ¬¾å’Œæ¡ä»¶ã€‚å¦‚æœä½¿ç”¨è€…æ— æ³•æ¥å—æœ¬å…è´£å£°æ˜çš„ä»»ä½•éƒ¨åˆ†ï¼Œè¯·å‹¿ä½¿ç”¨æœ¬æ•°æ®é›†ã€‚

## ğŸ¤ Disclaimer
- SA-Med2D-20M is composed of multiple publicly available datasets and aims to provide a resource for academic and technical research to researchers and developers. Any individual or organization (hereinafter referred to as "User") using this dataset must comply with the following disclaimer:
1. Dataset Source: SA-Med2D-20M is composed of multiple publicly available datasets, and the sources of these datasets have been clearly indicated in the preprint paper. Users should adhere to the relevant licenses and terms of use of the original datasets.
2. Data Accuracy: While efforts have been made to ensure the accuracy and completeness of the dataset, no guarantee can be given regarding its accuracy. Users assume all risks and liabilities associated with the use of the dataset.
3. Limitation of Liability: Under no circumstances shall the dataset providers or contributors be held liable for any actions or outcomes of the Users.
4. Usage Constraints: Users must comply with applicable laws, regulations, and ethical norms when using this dataset. The dataset must not be used for illegal, privacy-infringing, defamatory, discriminatory, or other unlawful or unethical purposes.
5. Intellectual Property: The intellectual property rights of this dataset belong to the relevant rights holders of the original datasets. Users must not infringe upon the intellectual property rights of the dataset in any way.

- As a non-profit organization, we advocate for a harmonious and friendly open-source communication environment. If any content in the open dataset is found to infringe upon your legitimate rights and interests, you can send an email to (yejin@pilab.org.cn, chengjunlong@pilab.org.cn) with a detailed description of the infringement and provide relevant ownership proof materials. We will initiate an investigation and handling mechanism within three working days and take necessary measures (such as removing relevant data) if warranted. However, the authenticity of your complaint must be ensured, as any adverse consequences resulting from the measures taken shall be borne solely by you.

- By downloading, copying, accessing, or using this dataset, the User indicates that they have read, understood, and agreed to comply with all the terms and conditions of this disclaimer. If the User cannot accept any part of this disclaimer, please refrain from using this dataset.

## ğŸ¤ Acknowledgement
- We thank all medical workers and dataset owners for making public datasets available to the community. If you find that your dataset is included in our SA-Med2D-20M but you do not want us to do so, please contact us to remove it.

## ğŸ‘‹ Hiring & Global Collaboration
- **Hiring:** We are hiring researchers, engineers, and interns in General Vision Group, Shanghai AI Lab. If you are interested in Medical Foundation Models and General Medical AI, including designing benchmark datasets, general models, evaluation systems, and efficient tools, please contact us.
- **Global Collaboration:** We're on a mission to redefine medical research, aiming for a more universally adaptable model. Our passionate team is delving into foundational healthcare models, promoting the development of the medical community. Collaborate with us to increase competitiveness, reduce risk, and expand markets.
- **Contact:** Junjun He(hejunjun@pjlab.org.cn), Jin Ye(yejin@pjlab.org.cn), and Tianbin Li (litianbin@pjlab.org.cn).

## ğŸ‘‰ Typos of paper
1. Formula (1) is incorrect, after correction: <img src="https://i.postimg.cc/sXRK4MKh/20231123001020.png" alt="alt text" width="202" height="50">

## Reference
```
@misc{ye2023samed2d20m,
      title={SA-Med2D-20M Dataset: Segment Anything in 2D Medical Imaging with 20 Million masks}, 
      author={Jin Ye and Junlong Cheng and Jianpin Chen and Zhongying Deng and Tianbin Li and Haoyu Wang and Yanzhou Su and Ziyan Huang and Jilong Chen and Lei Jiang and Hui Sun and Min Zhu and Shaoting Zhang and Junjun He and Yu Qiao},
      year={2023},
      eprint={2311.11969},
      archivePrefix={arXiv},
      primaryClass={eess.IV}
}

@misc{cheng2023sammed2d,
      title={SAM-Med2D}, 
      author={Junlong Cheng and Jin Ye and Zhongying Deng and Jianpin Chen and Tianbin Li and Haoyu Wang and Yanzhou Su and
              Ziyan Huang and Jilong Chen and Lei Jiangand Hui Sun and Junjun He and Shaoting Zhang and Min Zhu and Yu Qiao},
      year={2023},
      eprint={2308.16184},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```
